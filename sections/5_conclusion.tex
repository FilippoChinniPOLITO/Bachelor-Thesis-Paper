\chapter{Conclusions}

The results of the experiments allowed to reach significant conclusions about Hyperparamter Optimization and its related techniques. The work was able to outline the importance of HPO, and evaluate its effectiveness in various contexts, with the use of popular and new techniques.

\section{Summary of the Results}

In Experiment 1, it was possible demonstrate that HPO is a powerful strategy to improve the performance of machine learning models; improvements in the performance were clearly observable in the results of the experiments, showing that emphirical or random approaches to the Tuning of Hyperparameters are not as effective as a formal optimization process such as HPO.
\\[0.3cm]In Experiment 2, the applicability of a HPO's library, Optuna, was tested and evaluated. In particular, different HPO algorithms (those with an implementation in Optuna) were tested and compared on the classic MNIST dataset. The results showed that the TPE sampler was the most effective in this case, but it is vital to note that the performance of the algorithms may vary depending on the dataset and the model being used. It was also observed that a simple method as the Random Seach can be utilized as a baseline for the comparison of other HPO algorithms.
\\[0.3cm]In Experiment 3, using an approach basically identical to Optuna's, a framework for HPO's was built, which used Particle Swarm Optimization (PSO) as the sampling algorithm. The results showed that the PSO algorithm was not as effective as the TPE sampler from Optuna, but it was still able to improve the performance of the models, reaching similar levels of quality in the performance. The experiment also demonstrated that building a framework for HPO is a viable strategy, and can save time and effort in the preparation phase of a Hyperparameters Tuning process.
\\[0.3cm]In Experiment 4, a sampler using the PSO algorithm was implemented in Optuna. Firstly, the implementation of the sampler was revealed as a success, integrating the PSO algorithm into the Optuna library. Secondly, the results of the experiments showed that the created PSO sampler reached similar performance levels to the TPE sampler, even surpassing it in some cases. This further demonstrated the effectiveness of the PSO algorithm as a sampling method for HPO.
\\[0.3cm]In Experiment 5, the strategies utilized so far were tested on a more complex dataset, the Weed Map dataset. The results allowed in the first place not only to find the best hyperparameters for the WeedMap problem, but also to simplify the architecture of the Nueral Network used in the experiment, with a comparatevely small loss in the performance of the model. The results also showed, not without struggles, that the HPO algorithms were able to work effectively also in a more complex situation, in particular, PSO can be now considered a valid alternative to the TPE sampler in the Optuna library, and in general a top-level sampling technique in HPO. 

\section{Limitations}

There are some limitations in the presented results which need to be considered. These limitations are mainly related to intrinsic complexity of HPO from the computational cost point of view.
\\[0.3cm]In general, all strategies revealed themselves effective only when a large number of trials were performed, and obviously, the more trials are performed, the more time is needed, and the more time is needed, the more computational resources are required to make the process feasible. This limitation in particularly evident when using the PSO sampler, which showed, most of the times, to require more trials than the TPE sampler to reach good level of performance.
The limitation did not impact the results of the first four experiments, as both the model and the dataset were simple, therefore less time to complete a single trial, and less total trials required. The problems however, became evident in the last experiment, where the complexity of the dataset and the model required a large number of trials to reach a good level of performance. Even with a relatively good, but not excellent, hardware, the time required to complete the trials was significantly higher than in the previous experiments, and this led to the necessity of reducing the number of trials to perform, so as to make the process feasible in a reasonable amount of time (below weeks).
\\[0.3cm]Another limitation to be considered, is the lack of a more detailed analysis of other HPO algorithms, starting from the ones implemented in Optuna which were given less importance in the experiments. As for the objectives of the experiments, it was not really necessary to test all the algorithms available in Optuna deeply, therefore when one technique showed problmes, for the sake of simplicity, it was decided to ignore it and move on. This limitation actually reduces the generalizability of the results, especially for what concerns Experiment 2.

\section{Recommendations for the Future}

Potential future work should focus on addressing the limitations of the current work, and on further exploring the potential of HPO and its related techniques.
\\[0.3cm]A first reccomendation is to reproduce Experiments 2 and 4 on a more complex dataset, additionally, more HPO algorithms should be tested and compared, both coming from Optuna and implementing them from scratch.
\\[0.3cm]A second recommendation is to execute Experiment 5 on a top-level hardware, in order to execute the optimization with more trials. This would allow to reach a better level of performance, and to better compare the PSO sampler with the TPE sampler.
\\[0.3cm]The results of Experiment 4 are a fundamental baseline for a potential pull-request to the Optuna library, in order to integrate the PSO sampler in the official release of the library. This would allow to make the PSO sampler available to a wider audience. Before doing this, however, it is recommended to further test the sampler on different datasets and models, in order to ensure its effectiveness in different contexts.
\\[0.3cm]Hyperparamter Optimization is a sub-field of Machine Learning which is still in its infancy, its main limitation lies in the computational cost required to perform the optimization. In the future, hardware might be able to overcome this limitation, by then reasearch in HPO should focus on the development of more efficient algorithms, adapting already existing optimization techniques or creating new ones specifically designed for HPO.   